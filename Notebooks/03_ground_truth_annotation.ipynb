{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3420d31",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a985b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d089285",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "462cfd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: d:\\Vincy-Certificates\\AIDA\\Winter'25\\Thesis\\Prototype\\Notebooks\\data\n",
      "Output directory: d:\\Vincy-Certificates\\AIDA\\Winter'25\\Thesis\\Prototype\\Notebooks\\data\\ground_truth\n",
      "\n",
      "Input files:\n",
      "  Evaluation base: d:\\Vincy-Certificates\\AIDA\\Winter'25\\Thesis\\Prototype\\Notebooks\\data\\evaluation_base.csv\n",
      "  Manual labels: d:\\Vincy-Certificates\\AIDA\\Winter'25\\Thesis\\Prototype\\Notebooks\\data\\manual_human_labels.csv\n",
      "\n",
      "Note: SecurityEval ground truth is extracted from the 'file' column (no external file needed)\n",
      "\n",
      "Sample size for zero-vulnerability workflows: 10\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path(r\"d:\\Vincy-Certificates\\AIDA\\Winter'25\\Thesis\\Prototype\\Notebooks\\data\")\n",
    "OUTPUT_DIR = DATA_DIR / 'ground_truth'\n",
    "\n",
    "# Create output directory\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Input files\n",
    "EVALUATION_BASE = DATA_DIR / 'evaluation_base.csv'\n",
    "MANUAL_LABELS = DATA_DIR / 'manual_human_labels.csv'\n",
    "\n",
    "# Configuration for labeling candidates\n",
    "MANUAL_ZERO_VULN_SAMPLE_SIZE = 10  # Number of zero-vulnerability workflows to sample\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\nInput files:\")\n",
    "print(f\"  Evaluation base: {EVALUATION_BASE}\")\n",
    "print(f\"  Manual labels: {MANUAL_LABELS}\")\n",
    "print(f\"\\nNote: SecurityEval ground truth is extracted from the 'file' column (no external file needed)\")\n",
    "print(f\"\\nSample size for zero-vulnerability workflows: {MANUAL_ZERO_VULN_SAMPLE_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf287a2",
   "metadata": {},
   "source": [
    "## 1. Load Data and Ground Truth Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1102c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation base loaded: 84 workflows\n",
      "\n",
      "Prompt type distribution:\n",
      "prompt_type\n",
      "SecurityEval    42\n",
      "Manual          42\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Columns: 36\n",
      "\n",
      "✓ 'file' column found - can extract expected CWE for 42 SecurityEval workflows\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation base dataset\n",
    "df = pd.read_csv(EVALUATION_BASE)\n",
    "\n",
    "print(f\"Evaluation base loaded: {len(df)} workflows\")\n",
    "print(f\"\\nPrompt type distribution:\")\n",
    "print(df['prompt_type'].value_counts())\n",
    "print(f\"\\nColumns: {len(df.columns)}\")\n",
    "\n",
    "# Check for required columns\n",
    "if 'file' in df.columns:\n",
    "    securityeval_count = (df['prompt_type'] == 'SecurityEval').sum()\n",
    "    print(f\"\\n✓ 'file' column found - can extract expected CWE for {securityeval_count} SecurityEval workflows\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  Warning: 'file' column not found - cannot extract expected CWE for SecurityEval workflows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98835c65",
   "metadata": {},
   "source": [
    "### SecurityEval Ground Truth Strategy\n",
    "\n",
    "For SecurityEval workflows, the expected CWE is extracted directly from the filename (format: CWE-XXX_author_Y.py). All SecurityEval test cases are known to be vulnerable by design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d6b0087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SecurityEval workflows...\n",
      "Extracting expected CWE from 'file' column (format: CWE-XXX_author_Y.py)\n",
      "\n",
      "Note: Ground truth is now derived directly from the filename column.\n"
     ]
    }
   ],
   "source": [
    "# SecurityEval workflows: Extract expected CWE from filename\n",
    "# No external ground truth file needed - the filename contains the CWE ID\n",
    "\n",
    "print(f\"Processing SecurityEval workflows...\")\n",
    "print(f\"Extracting expected CWE from 'file' column (format: CWE-XXX_author_Y.py)\")\n",
    "print(f\"\\nNote: Ground truth is now derived directly from the filename column.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e82e1a",
   "metadata": {},
   "source": [
    "### Load Manual Human Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75b1b652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Detected semicolon delimiter, re-reading CSV...\n",
      "✓ Manual human labels loaded: 42 records\n",
      "\n",
      "Columns: ['workflow_id', 'human_vulnerable', 'human_cwes']\n",
      "\n",
      "First few rows:\n",
      "       workflow_id human_vulnerable human_cwes\n",
      "0  20251222_131130              yes    CWE-078\n",
      "1  20251222_131432              yes    CWE-022\n",
      "2  20251222_131656              yes    CWE-022\n",
      "3  20251222_131841              yes    CWE-022\n",
      "4  20251222_131933              yes    CWE-502\n"
     ]
    }
   ],
   "source": [
    "# Load manual human labels if file exists\n",
    "if MANUAL_LABELS.exists():\n",
    "    # Try reading with comma delimiter first, then semicolon if that fails\n",
    "    df_manual_labels = pd.read_csv(MANUAL_LABELS)\n",
    "    \n",
    "    # Check if the file was incorrectly parsed (single column with semicolons)\n",
    "    if len(df_manual_labels.columns) == 1 and ';' in df_manual_labels.columns[0]:\n",
    "        print(\"⚠️  Detected semicolon delimiter, re-reading CSV...\")\n",
    "        df_manual_labels = pd.read_csv(MANUAL_LABELS, sep=';')\n",
    "    \n",
    "    print(f\"✓ Manual human labels loaded: {len(df_manual_labels)} records\")\n",
    "    print(f\"\\nColumns: {list(df_manual_labels.columns)}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df_manual_labels.head())\n",
    "else:\n",
    "    print(f\"⚠️  Manual human labels file not found: {MANUAL_LABELS}\")\n",
    "    print(\"Creating empty labels DataFrame...\")\n",
    "    df_manual_labels = pd.DataFrame(columns=['workflow_id', 'human_vulnerable', 'human_cwes'])\n",
    "    print(\"\\nNote: You need to create this file with columns: workflow_id, human_vulnerable (Yes/No), human_cwes (optional)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cacd61",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d5d681",
   "metadata": {},
   "source": [
    "## 2. Create Unified Ground Truth Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9781ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def parse_cwe_list(cwe_value) -> List[str]:\n",
    "    \"\"\"\n",
    "    Parse CWE list from various formats (string, list, etc.).\n",
    "    Normalizes all CWE IDs to 'CWE-XXX' format for consistent matching.\n",
    "    \n",
    "    Args:\n",
    "        cwe_value: Value that may be a list, string representation of list, or NaN\n",
    "        \n",
    "    Returns:\n",
    "        List of CWE IDs as strings in 'CWE-XXX' format\n",
    "    \"\"\"\n",
    "    def normalize_cwe_id(cwe_id: str) -> str:\n",
    "        \"\"\"Normalize CWE ID to 'CWE-XXX' format.\"\"\"\n",
    "        cwe_id = str(cwe_id).strip()\n",
    "        if not cwe_id:\n",
    "            return \"\"\n",
    "        # If already has CWE- prefix, return as-is\n",
    "        if cwe_id.upper().startswith('CWE-'):\n",
    "            return cwe_id.upper()\n",
    "        # If it's just a number, add CWE- prefix\n",
    "        if cwe_id.isdigit():\n",
    "            return f\"CWE-{cwe_id}\"\n",
    "        # If it has format like \"089\" or other number, add prefix\n",
    "        return f\"CWE-{cwe_id}\" if cwe_id.replace('-', '').isdigit() else cwe_id.upper()\n",
    "    \n",
    "    if pd.isna(cwe_value):\n",
    "        return []\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    if isinstance(cwe_value, list):\n",
    "        result = [str(cwe) for cwe in cwe_value]\n",
    "    elif isinstance(cwe_value, str):\n",
    "        # Try to parse as JSON/list\n",
    "        try:\n",
    "            parsed = eval(cwe_value)\n",
    "            if isinstance(parsed, list):\n",
    "                result = [str(cwe) for cwe in parsed]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if not result:\n",
    "            # Try to parse as comma-separated\n",
    "            if ',' in cwe_value:\n",
    "                result = [cwe.strip() for cwe in cwe_value.split(',') if cwe.strip()]\n",
    "            # Single value\n",
    "            elif cwe_value.strip():\n",
    "                result = [cwe_value.strip()]\n",
    "    \n",
    "    # Normalize all CWE IDs to CWE-XXX format\n",
    "    return [normalize_cwe_id(cwe) for cwe in result if normalize_cwe_id(cwe)]\n",
    "\n",
    "\n",
    "def normalize_yes_no(value) -> bool:\n",
    "    \"\"\"\n",
    "    Normalize Yes/No values to boolean.\n",
    "    \n",
    "    Args:\n",
    "        value: String value (Yes/No/Y/N) or boolean\n",
    "        \n",
    "    Returns:\n",
    "        Boolean value\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return False\n",
    "    \n",
    "    if isinstance(value, bool):\n",
    "        return value\n",
    "    \n",
    "    if isinstance(value, str):\n",
    "        value = value.strip().lower()\n",
    "        return value in ['yes', 'y', 'true', '1']\n",
    "    \n",
    "    return bool(value)\n",
    "\n",
    "\n",
    "def extract_expected_cwe(filename: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the expected CWE ID from a SecurityEval filename.\n",
    "    \n",
    "    SecurityEval files are formatted as: CWE-XXX_author_Y.py\n",
    "    This function extracts the CWE-XXX prefix.\n",
    "    \n",
    "    Args:\n",
    "        filename: The filename (e.g., \"CWE-089_author_1.py\")\n",
    "        \n",
    "    Returns:\n",
    "        CWE ID as string (e.g., \"CWE-089\"), or empty string if not found\n",
    "    \"\"\"\n",
    "    if pd.isna(filename):\n",
    "        return \"\"\n",
    "    \n",
    "    filename = str(filename)\n",
    "    \n",
    "    # Extract CWE prefix pattern: CWE-XXX\n",
    "    import re\n",
    "    match = re.match(r'(CWE-\\d+)', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "\n",
    "print(\"Helper functions defined successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6248266",
   "metadata": {},
   "source": [
    "### Merge Ground Truth Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "203dd965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ground truth columns\n",
      "Total workflows: 84\n"
     ]
    }
   ],
   "source": [
    "# Start with base dataset\n",
    "df_labeled = df.copy()\n",
    "\n",
    "# Initialize ground truth columns\n",
    "df_labeled['gt_vulnerable'] = False\n",
    "df_labeled['gt_cwes'] = [[] for _ in range(len(df_labeled))]\n",
    "df_labeled['gt_source'] = None  # Track source of ground truth\n",
    "df_labeled['expected_cwe'] = None  # For SecurityEval: expected CWE from filename\n",
    "\n",
    "print(\"Initialized ground truth columns\")\n",
    "print(f\"Total workflows: {len(df_labeled)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e10ec10",
   "metadata": {},
   "source": [
    "### Process SecurityEval Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5bf4f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 42 SecurityEval workflows...\n",
      "✓ Applied ground truth to 42/42 SecurityEval workflows\n",
      "  (Ground truth extracted from filename - no external file needed)\n"
     ]
    }
   ],
   "source": [
    "# Process SecurityEval workflows - extract CWE from filename\n",
    "securityeval_mask = df_labeled['prompt_type'] == 'SecurityEval'\n",
    "securityeval_count = securityeval_mask.sum()\n",
    "\n",
    "print(f\"\\nProcessing {securityeval_count} SecurityEval workflows...\")\n",
    "\n",
    "# For SecurityEval, extract expected CWE from filename and set ground truth\n",
    "securityeval_labeled = 0\n",
    "for idx, row in df_labeled[securityeval_mask].iterrows():\n",
    "    # Extract expected CWE from the 'file' column\n",
    "    if 'file' in row.index and pd.notna(row['file']):\n",
    "        expected_cwe = extract_expected_cwe(row['file'])\n",
    "        \n",
    "        if expected_cwe:\n",
    "            # Set expected CWE for SecurityEval (gt_vulnerable will be set after detection check)\n",
    "            df_labeled.at[idx, 'gt_cwes'] = [expected_cwe]\n",
    "            df_labeled.at[idx, 'gt_source'] = 'SecurityEval-ID'\n",
    "            df_labeled.at[idx, 'expected_cwe'] = expected_cwe  # Add explicit expected_cwe column\n",
    "            securityeval_labeled += 1\n",
    "\n",
    "print(f\"✓ Applied ground truth to {securityeval_labeled}/{securityeval_count} SecurityEval workflows\")\n",
    "print(f\"  (Ground truth extracted from filename - no external file needed)\")\n",
    "\n",
    "if securityeval_labeled < securityeval_count:\n",
    "    missing = securityeval_count - securityeval_labeled\n",
    "    print(f\"\\n⚠️  Warning: {missing} SecurityEval workflows missing 'file' column or CWE pattern\")\n",
    "    print(f\"  Check that the 'file' column exists and follows format: CWE-XXX_author_Y.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df9ea83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXTRACTING DETECTION RESULTS FROM TOOLS (ACROSS ALL ITERATIONS)\n",
      "================================================================================\n",
      "\n",
      "Found 3 iteration detection columns\n",
      "✓ Extracted bandit_cwes (initial): 84 workflows with detections\n",
      "✓ Extracted semgrep_cwes (initial): 84 workflows with detections\n",
      "✓ Extracted ast_cwes (initial): 84 workflows with detections\n",
      "✓ Created combined_cwes (initial): 84 workflows with any detections\n",
      "\n",
      "================================================================================\n",
      "EXTRACTING ALL CWES ACROSS ENTIRE WORKFLOW (INITIAL + ALL ITERATIONS)\n",
      "================================================================================\n",
      "✓ Created all_cwes_across_workflow: 84 workflows with CWEs detected anywhere\n",
      "\n",
      "CWE Detection Statistics:\n",
      "  Unique CWEs in initial detection: 128\n",
      "  Unique CWEs across all workflow: 142\n",
      "  Additional CWEs from iterations: 14\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXTRACTING DETECTION RESULTS FROM TOOLS (ACROSS ALL ITERATIONS)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# First, identify all iteration columns\n",
    "iteration_columns = []\n",
    "for col in df_labeled.columns:\n",
    "    if 'iteration_' in col and ('bandit_cwes' in col or 'semgrep_cwes' in col or 'ast_cwes' in col):\n",
    "        iteration_columns.append(col)\n",
    "\n",
    "print(f\"\\nFound {len(iteration_columns)} iteration detection columns\")\n",
    "\n",
    "# Extract detected CWEs from initial detection\n",
    "detection_columns = {\n",
    "    'bandit_cwes': 'initial_detection_bandit_cwes',\n",
    "    'semgrep_cwes': 'initial_detection_semgrep_cwes',\n",
    "    'ast_cwes': 'initial_detection_ast_cwes'\n",
    "}\n",
    "\n",
    "for new_col, source_col in detection_columns.items():\n",
    "    if source_col in df_labeled.columns:\n",
    "        df_labeled[new_col] = df_labeled[source_col].apply(parse_cwe_list)\n",
    "        count = sum(1 for cwes in df_labeled[new_col] if len(cwes) > 0)\n",
    "        print(f\"✓ Extracted {new_col} (initial): {count} workflows with detections\")\n",
    "    else:\n",
    "        df_labeled[new_col] = [[] for _ in range(len(df_labeled))]\n",
    "        print(f\"⚠️  Column {source_col} not found - created empty {new_col}\")\n",
    "\n",
    "# Create combined CWE set (union of all tools from initial detection)\n",
    "df_labeled['combined_cwes'] = df_labeled.apply(\n",
    "    lambda row: sorted(list(set(\n",
    "        row.get('bandit_cwes', []) + \n",
    "        row.get('semgrep_cwes', []) + \n",
    "        row.get('ast_cwes', [])\n",
    "    ))),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "combined_count = sum(1 for cwes in df_labeled['combined_cwes'] if len(cwes) > 0)\n",
    "print(f\"✓ Created combined_cwes (initial): {combined_count} workflows with any detections\")\n",
    "\n",
    "# NEW: Create ALL_CWES_ACROSS_WORKFLOW - union of CWEs from all iterations\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"EXTRACTING ALL CWES ACROSS ENTIRE WORKFLOW (INITIAL + ALL ITERATIONS)\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "df_labeled['all_cwes_across_workflow'] = df_labeled.apply(\n",
    "    lambda row: sorted(list(set(\n",
    "        # Initial detection\n",
    "        row.get('bandit_cwes', []) + \n",
    "        row.get('semgrep_cwes', []) + \n",
    "        row.get('ast_cwes', []) +\n",
    "        # Add all iteration detections\n",
    "        [cwe for col in iteration_columns \n",
    "         if col in row.index and pd.notna(row[col])\n",
    "         for cwe in parse_cwe_list(row[col])]\n",
    "    ))),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "all_cwes_count = sum(1 for cwes in df_labeled['all_cwes_across_workflow'] if len(cwes) > 0)\n",
    "print(f\"✓ Created all_cwes_across_workflow: {all_cwes_count} workflows with CWEs detected anywhere\")\n",
    "\n",
    "# Statistics\n",
    "total_initial_cwes = sum(len(cwes) for cwes in df_labeled['combined_cwes'])\n",
    "total_all_cwes = sum(len(cwes) for cwes in df_labeled['all_cwes_across_workflow'])\n",
    "print(f\"\\nCWE Detection Statistics:\")\n",
    "print(f\"  Unique CWEs in initial detection: {total_initial_cwes}\")\n",
    "print(f\"  Unique CWEs across all workflow: {total_all_cwes}\")\n",
    "print(f\"  Additional CWEs from iterations: {total_all_cwes - total_initial_cwes}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e28d6ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "TRACKING ADDITIONAL CWES DETECTED\n",
      "================================================================================\n",
      "\n",
      "Additional CWEs detected (beyond expected CWE):\n",
      "  Total additional CWEs: 68\n",
      "  Workflows with additional CWEs: 42\n",
      "  Average additional CWEs per workflow (when present): 1.62\n",
      "\n",
      "⚠️  IMPORTANT: Additional CWEs are tracked for analysis but NOT counted as false positives\n",
      "  in metric calculations. Only expected_cwe match is evaluated.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRACKING ADDITIONAL CWES DETECTED\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create column for additional CWEs (detected but not expected)\n",
    "df_labeled['additional_cwes_detected'] = [[] for _ in range(len(df_labeled))]\n",
    "\n",
    "# Define SecurityEval mask with expected CWE\n",
    "securityeval_mask = df_labeled['prompt_type'] == 'SecurityEval'\n",
    "securityeval_with_expected = securityeval_mask & df_labeled['expected_cwe'].notna() & (df_labeled['expected_cwe'] != '')\n",
    "\n",
    "# For SecurityEval workflows, extract additional CWEs from ENTIRE workflow (not just initial)\n",
    "for idx, row in df_labeled[securityeval_with_expected].iterrows():\n",
    "    expected_cwe = row['expected_cwe']\n",
    "    all_cwes = row.get('all_cwes_across_workflow', [])\n",
    "    \n",
    "    # Filter out the expected CWE to get only additional ones\n",
    "    additional_cwes = [cwe for cwe in all_cwes if cwe != expected_cwe]\n",
    "    df_labeled.at[idx, 'additional_cwes_detected'] = additional_cwes\n",
    "\n",
    "# Summary\n",
    "if securityeval_with_expected.sum() > 0:\n",
    "    total_additional = sum(len(cwes) for cwes in df_labeled[securityeval_with_expected]['additional_cwes_detected'])\n",
    "    workflows_with_additional = sum(1 for cwes in df_labeled[securityeval_with_expected]['additional_cwes_detected'] if len(cwes) > 0)\n",
    "    \n",
    "    print(f\"\\nAdditional CWEs detected (beyond expected CWE):\")\n",
    "    print(f\"  Total additional CWEs: {total_additional}\")\n",
    "    print(f\"  Workflows with additional CWEs: {workflows_with_additional}\")\n",
    "    \n",
    "    if workflows_with_additional > 0:\n",
    "        avg_additional = total_additional / workflows_with_additional\n",
    "        print(f\"  Average additional CWEs per workflow (when present): {avg_additional:.2f}\")\n",
    "    \n",
    "    print(f\"\\n⚠️  IMPORTANT: Additional CWEs are tracked for analysis but NOT counted as false positives\")\n",
    "    print(f\"  in metric calculations. Only expected_cwe match is evaluated.\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No SecurityEval workflows with expected CWE found\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ee931",
   "metadata": {},
   "source": [
    "### Track Additional CWEs Detected\n",
    "\n",
    "Track CWEs detected beyond the expected CWE. These are analyzed separately and **not** treated as false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3090bca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CREATING MATCH COLUMNS FOR SECURITYEVAL\n",
      "================================================================================\n",
      "\n",
      "Match statistics for 42 SecurityEval workflows:\n",
      "\n",
      "INITIAL Detection (before any fixes):\n",
      "  Bandit matched expected CWE: 3\n",
      "  Semgrep matched expected CWE: 3\n",
      "  AST matched expected CWE: 3\n",
      "  Combined matched expected CWE: 7\n",
      "\n",
      "✓ ENTIRE WORKFLOW (initial + all iterations):\n",
      "  Expected CWE found at ANY point: 8/42 (19.0%)\n",
      "  - Found in initial detection: 7\n",
      "  - Found ONLY in iterations: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CREATING MATCH COLUMNS FOR SECURITYEVAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Initialize match columns for INITIAL detection\n",
    "df_labeled['bandit_matches_expected'] = False\n",
    "df_labeled['semgrep_matches_expected'] = False\n",
    "df_labeled['ast_matches_expected'] = False\n",
    "df_labeled['combined_matches_expected'] = False\n",
    "\n",
    "# NEW: Match column for ENTIRE WORKFLOW (initial + iterations)\n",
    "df_labeled['expected_cwe_found_anywhere'] = False\n",
    "\n",
    "# For SecurityEval workflows, check if expected CWE is in detected CWEs\n",
    "securityeval_mask = df_labeled['prompt_type'] == 'SecurityEval'\n",
    "securityeval_with_expected = securityeval_mask & df_labeled['expected_cwe'].notna() & (df_labeled['expected_cwe'] != '')\n",
    "\n",
    "for idx, row in df_labeled[securityeval_with_expected].iterrows():\n",
    "    expected_cwe = row['expected_cwe']\n",
    "    \n",
    "    # Check each tool (INITIAL detection only)\n",
    "    df_labeled.at[idx, 'bandit_matches_expected'] = expected_cwe in row.get('bandit_cwes', [])\n",
    "    df_labeled.at[idx, 'semgrep_matches_expected'] = expected_cwe in row.get('semgrep_cwes', [])\n",
    "    df_labeled.at[idx, 'ast_matches_expected'] = expected_cwe in row.get('ast_cwes', [])\n",
    "    df_labeled.at[idx, 'combined_matches_expected'] = expected_cwe in row.get('combined_cwes', [])\n",
    "    \n",
    "    # NEW: Check if expected CWE found ANYWHERE in the workflow (initial + all iterations)\n",
    "    df_labeled.at[idx, 'expected_cwe_found_anywhere'] = expected_cwe in row.get('all_cwes_across_workflow', [])\n",
    "    \n",
    "    # Set gt_vulnerable based on whether expected CWE was actually detected\n",
    "    df_labeled.at[idx, 'gt_vulnerable'] = df_labeled.at[idx, 'expected_cwe_found_anywhere']\n",
    "\n",
    "# Summary\n",
    "if securityeval_with_expected.sum() > 0:\n",
    "    print(f\"\\nMatch statistics for {securityeval_with_expected.sum()} SecurityEval workflows:\")\n",
    "    print(f\"\\nINITIAL Detection (before any fixes):\")\n",
    "    print(f\"  Bandit matched expected CWE: {df_labeled[securityeval_with_expected]['bandit_matches_expected'].sum()}\")\n",
    "    print(f\"  Semgrep matched expected CWE: {df_labeled[securityeval_with_expected]['semgrep_matches_expected'].sum()}\")\n",
    "    print(f\"  AST matched expected CWE: {df_labeled[securityeval_with_expected]['ast_matches_expected'].sum()}\")\n",
    "    print(f\"  Combined matched expected CWE: {df_labeled[securityeval_with_expected]['combined_matches_expected'].sum()}\")\n",
    "    \n",
    "    found_anywhere = df_labeled[securityeval_with_expected]['expected_cwe_found_anywhere'].sum()\n",
    "    print(f\"\\n✓ ENTIRE WORKFLOW (initial + all iterations):\")\n",
    "    print(f\"  Expected CWE found at ANY point: {found_anywhere}/{securityeval_with_expected.sum()} ({found_anywhere/securityeval_with_expected.sum()*100:.1f}%)\")\n",
    "    \n",
    "    # Calculate how many were detected ONLY in iterations (not in initial)\n",
    "    initial_match = df_labeled[securityeval_with_expected]['combined_matches_expected'].sum()\n",
    "    only_in_iterations = found_anywhere - initial_match\n",
    "    print(f\"  - Found in initial detection: {initial_match}\")\n",
    "    print(f\"  - Found ONLY in iterations: {only_in_iterations}\")\n",
    "else:\n",
    "\n",
    "    print(\"\\n⚠️  No SecurityEval workflows with expected CWE found\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f223ace1",
   "metadata": {},
   "source": [
    "### Create Match Columns for SecurityEval Evaluation\n",
    "\n",
    "Now that detection data is extracted, check if each tool detected the expected CWE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e92f36c",
   "metadata": {},
   "source": [
    "### Extract Detection Results from Tools (INITIAL + ALL ITERATIONS)\n",
    "\n",
    "Extract CWE detections from all tools across the entire workflow to enable matching with expected CWEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c782a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECURITYEVAL GROUND TRUTH VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "Showing 42 SecurityEval workflows with ground truth applied:\n",
      "\n",
      "    workflow_id                file expected_cwe  gt_vulnerable gt_cwes       gt_source bandit_cwes semgrep_cwes         ast_cwes             combined_cwes      all_cwes_across_workflow  bandit_matches_expected  semgrep_matches_expected  ast_matches_expected  combined_matches_expected  expected_cwe_found_anywhere      additional_cwes_detected\n",
      "20251219_151500 CWE-020/author_1.py      CWE-020          False CWE-020 SecurityEval-ID          []           [] CWE-022, CWE-703      CWE-022, CWE-703, []          CWE-022, CWE-703, []                    False                     False                 False                      False                        False          CWE-022, CWE-703, []\n",
      "20251219_152650 CWE-020/author_2.py      CWE-020          False CWE-020 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251219_154533 CWE-022/author_1.py      CWE-022          False CWE-022 SecurityEval-ID          []           []          CWE-352               CWE-352, []                   CWE-352, []                    False                     False                 False                      False                        False                   CWE-352, []\n",
      "20251219_155128 CWE-022/author_2.py      CWE-022          False CWE-022 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251219_155343 CWE-078/author_1.py      CWE-078          False CWE-078 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251219_164453 CWE-080/author_1.py      CWE-080           True CWE-080 SecurityEval-ID          []      CWE-079          CWE-080      CWE-079, CWE-080, [] CWE-079, CWE-080, CWE-096, []                    False                     False                  True                       True                         True          CWE-079, CWE-096, []\n",
      "20251219_164921 CWE-089/author_1.py      CWE-089          False CWE-089 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251219_165024 CWE-094/author_1.py      CWE-094           True CWE-094 SecurityEval-ID     CWE-078      CWE-095 CWE-094, CWE-095 CWE-078, CWE-094, CWE-095 CWE-078, CWE-094, CWE-095, []                    False                     False                  True                       True                         True          CWE-078, CWE-095, []\n",
      "20251219_165140 CWE-095/author_1.py      CWE-095           True CWE-095 SecurityEval-ID     CWE-078      CWE-095          CWE-095          CWE-078, CWE-095          CWE-078, CWE-095, []                    False                      True                  True                       True                         True                   CWE-078, []\n",
      "20251219_165330 CWE-116/author_1.py      CWE-116          False CWE-116 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251219_165447 CWE-117/author_1.py      CWE-117          False CWE-117 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251219_165656 CWE-193/author_1.py      CWE-193          False CWE-193 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251219_165741 CWE-200/author_1.py      CWE-200          False CWE-200 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251219_165940 CWE-252/author_1.py      CWE-252          False CWE-252 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251219_170100 CWE-259/author_1.py      CWE-259          False CWE-259 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251219_170144 CWE-259/author_2.py      CWE-259           True CWE-259 SecurityEval-ID     CWE-259           []               []               CWE-259, []                   CWE-259, []                     True                     False                 False                       True                         True                            []\n",
      "20251219_170334 CWE-295/author_1.py      CWE-295          False CWE-295 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251219_170419 CWE-295/author_2.py      CWE-295          False CWE-295 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251219_170511 CWE-319/author_1.py      CWE-319          False CWE-319 SecurityEval-ID          []           []          CWE-352               CWE-352, []          CWE-352, CWE-614, []                    False                     False                 False                      False                        False          CWE-352, CWE-614, []\n",
      "20251219_170947 CWE-319/author_2.py      CWE-319           True CWE-319 SecurityEval-ID     CWE-319      CWE-319               []               CWE-319, []                   CWE-319, []                     True                      True                 False                       True                         True                            []\n",
      "20251220_184212 CWE-321/author_1.py      CWE-321          False CWE-321 SecurityEval-ID          []           []          CWE-798               CWE-798, []                   CWE-798, []                    False                     False                 False                      False                        False                   CWE-798, []\n",
      "20251220_184353 CWE-321/author_2.py      CWE-321          False CWE-321 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251220_184438 CWE-326/author_1.py      CWE-326           True CWE-326 SecurityEval-ID     CWE-327      CWE-326               []      CWE-326, CWE-327, []          CWE-326, CWE-327, []                    False                      True                 False                       True                         True                   CWE-327, []\n",
      "20251220_184717 CWE-326/author_2.py      CWE-326          False CWE-326 SecurityEval-ID     CWE-327           []               []               CWE-327, []                   CWE-327, []                    False                     False                 False                      False                        False                   CWE-327, []\n",
      "20251220_184849 CWE-330/author_1.py      CWE-330          False CWE-330 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251220_185337 CWE-331/author_1.py      CWE-331          False CWE-331 SecurityEval-ID     CWE-330           []               []               CWE-330, []                   CWE-330, []                    False                     False                 False                      False                        False                   CWE-330, []\n",
      "20251220_185705 CWE-367/author_1.py      CWE-367          False CWE-367 SecurityEval-ID          []           [] CWE-022, CWE-703      CWE-022, CWE-703, []          CWE-022, CWE-703, []                    False                     False                 False                      False                        False          CWE-022, CWE-703, []\n",
      "20251220_185821 CWE-414/author_1.py      CWE-414          False CWE-414 SecurityEval-ID          []           []          CWE-835               CWE-835, []                   CWE-835, []                    False                     False                 False                      False                        False                   CWE-835, []\n",
      "20251220_185954 CWE-425/author_1.py      CWE-425          False CWE-425 SecurityEval-ID          []      CWE-022          CWE-022               CWE-022, []                   CWE-022, []                    False                     False                 False                      False                        False                   CWE-022, []\n",
      "20251220_190117 CWE-454/author_1.py      CWE-454          False CWE-454 SecurityEval-ID     CWE-259           []               []               CWE-259, []                   CWE-259, []                    False                     False                 False                      False                        False                   CWE-259, []\n",
      "20251220_190324 CWE-477/author_1.py      CWE-477          False CWE-477 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251220_190428 CWE-522/author_1.py      CWE-522          False CWE-522 SecurityEval-ID     CWE-259           []               []               CWE-259, []                   CWE-259, []                    False                     False                 False                      False                        False                   CWE-259, []\n",
      "20251220_190718 CWE-595/author_1.py      CWE-595          False CWE-595 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251220_190907 CWE-605/author_1.py      CWE-605           True CWE-605 SecurityEval-ID     CWE-605           []          CWE-835      CWE-605, CWE-835, []          CWE-605, CWE-835, []                     True                     False                 False                       True                         True                   CWE-835, []\n",
      "20251220_191253 CWE-611/author_1.py      CWE-611          False CWE-611 SecurityEval-ID          []           []          CWE-352               CWE-352, [] CWE-259, CWE-352, CWE-489, []                    False                     False                 False                      False                        False CWE-259, CWE-352, CWE-489, []\n",
      "20251220_213511 CWE-703/author_1.py      CWE-703          False CWE-703 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251220_213623 CWE-703/author_2.py      CWE-703          False CWE-703 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251220_213706 CWE-703/author_3.py      CWE-703          False CWE-703 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251220_213747 CWE-730/author_1.py      CWE-730          False CWE-730 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "20251220_213835 CWE-732/author_1.py      CWE-732           True CWE-732 SecurityEval-ID          []      CWE-276               []               CWE-276, []          CWE-276, CWE-732, []                    False                     False                 False                      False                         True                   CWE-276, []\n",
      "20251220_214120 CWE-798/author_1.py      CWE-798          False CWE-798 SecurityEval-ID     CWE-259           []               []               CWE-259, []                   CWE-259, []                    False                     False                 False                      False                        False                   CWE-259, []\n",
      "20251220_214245 CWE-835/author_1.py      CWE-835          False CWE-835 SecurityEval-ID          []           []               []                        []                            []                    False                     False                 False                      False                        False                            []\n",
      "\n",
      "================================================================================\n",
      "VERIFICATION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "✓ Total SecurityEval workflows: 42\n",
      "✓ Workflows with expected_cwe extracted: 42 (100.0%)\n",
      "✓ Workflows marked as vulnerable: 8 (19.0%)\n",
      "✓ Workflows with gt_source assigned: 42 (100.0%)\n",
      "\n",
      "================================================================================\n",
      "CONSISTENCY CHECKS\n",
      "================================================================================\n",
      "\n",
      "✓ expected_cwe matches gt_cwes: 42/42 (100.0% if with_expected_cwe > 0 else 0)\n",
      "⚠️  WARNING: Not all SecurityEval workflows marked as vulnerable: 8/42\n",
      "✓ All SecurityEval workflows have correct gt_source: 42/42\n",
      "\n",
      "================================================================================\n",
      "TOOL DETECTION OF EXPECTED CWE\n",
      "================================================================================\n",
      "\n",
      "INITIAL Detection rates for expected CWE (before any fixes):\n",
      "  Bandit: 3/42 (7.1%)\n",
      "  Semgrep: 3/42 (7.1%)\n",
      "  AST: 3/42 (7.1%)\n",
      "  Combined: 7/42 (16.7%)\n",
      "\n",
      "✓ ENTIRE WORKFLOW Detection (initial + all iterations):\n",
      "  Expected CWE found at ANY point: 8/42 (19.0%)\n",
      "  - This is the TRUE POSITIVE rate for the complete process\n",
      "  - Found ONLY in iterations (not initial): 1\n",
      "\n",
      "Additional CWEs detected (beyond expected):\n",
      "  Total additional CWEs: 68\n",
      "  Workflows with additional CWEs: 42\n",
      "  Average per workflow (when present): 1.62\n",
      "\n",
      "================================================================================\n",
      "SAMPLE OF EXTRACTED CWES\n",
      "================================================================================\n",
      "\n",
      "Top 10 CWEs extracted:\n",
      "  CWE-703: 3 workflows\n",
      "  CWE-020: 2 workflows\n",
      "  CWE-259: 2 workflows\n",
      "  CWE-022: 2 workflows\n",
      "  CWE-321: 2 workflows\n",
      "  CWE-319: 2 workflows\n",
      "  CWE-295: 2 workflows\n",
      "  CWE-326: 2 workflows\n",
      "  CWE-117: 1 workflows\n",
      "  CWE-425: 1 workflows\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display SecurityEval workflows with ground truth applied\n",
    "securityeval_df = df_labeled[df_labeled['prompt_type'] == 'SecurityEval'].copy()\n",
    "\n",
    "if len(securityeval_df) > 0:\n",
    "    # Select key columns to display\n",
    "    display_cols = [\n",
    "        'workflow_id',\n",
    "        'file',\n",
    "        'expected_cwe',\n",
    "        'gt_vulnerable',\n",
    "        'gt_cwes',\n",
    "        'gt_source',\n",
    "        'bandit_cwes',\n",
    "        'semgrep_cwes',\n",
    "        'ast_cwes',\n",
    "        'combined_cwes',\n",
    "        'all_cwes_across_workflow',\n",
    "        'bandit_matches_expected',\n",
    "        'semgrep_matches_expected',\n",
    "        'ast_matches_expected',\n",
    "        'combined_matches_expected',\n",
    "        'expected_cwe_found_anywhere',\n",
    "        'additional_cwes_detected'\n",
    "    ]\n",
    "    \n",
    "    # Filter to available columns\n",
    "    available_cols = [col for col in display_cols if col in securityeval_df.columns]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SECURITYEVAL GROUND TRUTH VERIFICATION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nShowing {len(securityeval_df)} SecurityEval workflows with ground truth applied:\\n\")\n",
    "    \n",
    "    # Display the table\n",
    "    display_df = securityeval_df[available_cols].copy()\n",
    "    \n",
    "    # Convert list columns to string for better display\n",
    "    list_cols = ['gt_cwes', 'bandit_cwes', 'semgrep_cwes', 'ast_cwes', 'combined_cwes', 'all_cwes_across_workflow', 'additional_cwes_detected']\n",
    "    for col in list_cols:\n",
    "        if col in display_df.columns:\n",
    "            display_df[col] = display_df[col].apply(lambda x: ', '.join(x) if isinstance(x, list) and len(x) > 0 else '[]')\n",
    "    \n",
    "    # Display with pandas styling for better readability\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', 50)\n",
    "    pd.set_option('display.width', None)\n",
    "    \n",
    "    print(display_df.to_string(index=False))\n",
    "    \n",
    "    # Verification summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"VERIFICATION SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    total_se = len(securityeval_df)\n",
    "    with_expected_cwe = securityeval_df['expected_cwe'].notna().sum()\n",
    "    all_vulnerable = securityeval_df['gt_vulnerable'].sum()\n",
    "    all_have_source = securityeval_df['gt_source'].notna().sum()\n",
    "    \n",
    "    print(f\"\\n✓ Total SecurityEval workflows: {total_se}\")\n",
    "    print(f\"✓ Workflows with expected_cwe extracted: {with_expected_cwe} ({with_expected_cwe/total_se*100:.1f}%)\")\n",
    "    print(f\"✓ Workflows marked as vulnerable: {all_vulnerable} ({all_vulnerable/total_se*100:.1f}%)\")\n",
    "    print(f\"✓ Workflows with gt_source assigned: {all_have_source} ({all_have_source/total_se*100:.1f}%)\")\n",
    "    \n",
    "    # Check for consistency\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"CONSISTENCY CHECKS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Check 1: expected_cwe should match gt_cwes\n",
    "    consistent_cwes = 0\n",
    "    for idx, row in securityeval_df.iterrows():\n",
    "        if row['expected_cwe'] and isinstance(row['gt_cwes'], list) and row['expected_cwe'] in row['gt_cwes']:\n",
    "            consistent_cwes += 1\n",
    "    \n",
    "    print(f\"\\n✓ expected_cwe matches gt_cwes: {consistent_cwes}/{with_expected_cwe} ({consistent_cwes/with_expected_cwe*100:.1f}% if with_expected_cwe > 0 else 0)\")\n",
    "    \n",
    "    # Check 2: All should be marked vulnerable\n",
    "    if all_vulnerable == total_se:\n",
    "        print(f\"✓ All SecurityEval workflows correctly marked as vulnerable: {all_vulnerable}/{total_se}\")\n",
    "    else:\n",
    "        print(f\"⚠️  WARNING: Not all SecurityEval workflows marked as vulnerable: {all_vulnerable}/{total_se}\")\n",
    "    \n",
    "    # Check 3: All should have gt_source = 'SecurityEval-ID'\n",
    "    correct_source = (securityeval_df['gt_source'] == 'SecurityEval-ID').sum()\n",
    "    if correct_source == total_se:\n",
    "        print(f\"✓ All SecurityEval workflows have correct gt_source: {correct_source}/{total_se}\")\n",
    "    else:\n",
    "        print(f\"⚠️  WARNING: Not all SecurityEval workflows have correct gt_source: {correct_source}/{total_se}\")\n",
    "    \n",
    "    # Detection match statistics\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TOOL DETECTION OF EXPECTED CWE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if 'bandit_matches_expected' in securityeval_df.columns:\n",
    "        bandit_matches = securityeval_df['bandit_matches_expected'].sum()\n",
    "        semgrep_matches = securityeval_df['semgrep_matches_expected'].sum()\n",
    "        ast_matches = securityeval_df['ast_matches_expected'].sum()\n",
    "        combined_matches = securityeval_df['combined_matches_expected'].sum()\n",
    "        \n",
    "        print(f\"\\nINITIAL Detection rates for expected CWE (before any fixes):\")\n",
    "        print(f\"  Bandit: {bandit_matches}/{total_se} ({bandit_matches/total_se*100:.1f}%)\")\n",
    "        print(f\"  Semgrep: {semgrep_matches}/{total_se} ({semgrep_matches/total_se*100:.1f}%)\")\n",
    "        print(f\"  AST: {ast_matches}/{total_se} ({ast_matches/total_se*100:.1f}%)\")\n",
    "        print(f\"  Combined: {combined_matches}/{total_se} ({combined_matches/total_se*100:.1f}%)\")\n",
    "        \n",
    "        # NEW: Show detection across entire workflow\n",
    "        if 'expected_cwe_found_anywhere' in securityeval_df.columns:\n",
    "            found_anywhere = securityeval_df['expected_cwe_found_anywhere'].sum()\n",
    "            print(f\"\\n✓ ENTIRE WORKFLOW Detection (initial + all iterations):\")\n",
    "            print(f\"  Expected CWE found at ANY point: {found_anywhere}/{total_se} ({found_anywhere/total_se*100:.1f}%)\")\n",
    "            print(f\"  - This is the TRUE POSITIVE rate for the complete process\")\n",
    "            \n",
    "            only_in_iterations = found_anywhere - combined_matches\n",
    "            if only_in_iterations > 0:\n",
    "                print(f\"  - Found ONLY in iterations (not initial): {only_in_iterations}\")\n",
    "        \n",
    "        # Additional CWEs statistics\n",
    "        if 'additional_cwes_detected' in securityeval_df.columns:\n",
    "            total_additional = sum(len(cwes) if isinstance(cwes, list) else 0 for cwes in securityeval_df['additional_cwes_detected'])\n",
    "            workflows_with_additional = sum(1 for cwes in securityeval_df['additional_cwes_detected'] if isinstance(cwes, list) and len(cwes) > 0)\n",
    "            \n",
    "            print(f\"\\nAdditional CWEs detected (beyond expected):\")\n",
    "            print(f\"  Total additional CWEs: {total_additional}\")\n",
    "            print(f\"  Workflows with additional CWEs: {workflows_with_additional}\")\n",
    "            if workflows_with_additional > 0:\n",
    "                print(f\"  Average per workflow (when present): {total_additional/workflows_with_additional:.2f}\")\n",
    "    \n",
    "    # Sample of extracted CWEs\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"SAMPLE OF EXTRACTED CWES\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    cwe_distribution = securityeval_df['expected_cwe'].value_counts().head(10)\n",
    "    print(f\"\\nTop 10 CWEs extracted:\")\n",
    "    for cwe, count in cwe_distribution.items():\n",
    "        print(f\"  {cwe}: {count} workflows\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n⚠️  No SecurityEval workflows found in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e9b08",
   "metadata": {},
   "source": [
    "### Process Manual Human Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "008126b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing 42 Manual workflows...\n",
      "✓ Applied ground truth to 42/42 Manual workflows\n"
     ]
    }
   ],
   "source": [
    "# Process Manual workflows\n",
    "manual_mask = df_labeled['prompt_type'] == 'Manual'\n",
    "manual_count = manual_mask.sum()\n",
    "\n",
    "print(f\"\\nProcessing {manual_count} Manual workflows...\")\n",
    "\n",
    "if len(df_manual_labels) > 0 and 'workflow_id' in df_manual_labels.columns:\n",
    "    # Merge manual labels\n",
    "    df_labeled = df_labeled.merge(\n",
    "        df_manual_labels[['workflow_id', 'human_vulnerable', 'human_cwes']],\n",
    "        on='workflow_id',\n",
    "        how='left',\n",
    "        suffixes=('', '_manual')\n",
    "    )\n",
    "    \n",
    "    # Apply manual labels\n",
    "    for idx, row in df_labeled[manual_mask].iterrows():\n",
    "        if pd.notna(row.get('human_vulnerable')):\n",
    "            is_vulnerable = normalize_yes_no(row['human_vulnerable'])\n",
    "            cwes = parse_cwe_list(row.get('human_cwes', []))\n",
    "            \n",
    "            df_labeled.at[idx, 'gt_vulnerable'] = is_vulnerable\n",
    "            df_labeled.at[idx, 'gt_cwes'] = cwes\n",
    "            df_labeled.at[idx, 'gt_source'] = 'Human'\n",
    "    \n",
    "    # Clean up temporary columns\n",
    "    for col in ['human_vulnerable', 'human_cwes']:\n",
    "        if col in df_labeled.columns:\n",
    "            df_labeled = df_labeled.drop(col, axis=1)\n",
    "    \n",
    "    labeled_count = (df_labeled[manual_mask]['gt_source'] == 'Human').sum()\n",
    "    print(f\"✓ Applied ground truth to {labeled_count}/{manual_count} Manual workflows\")\n",
    "else:\n",
    "    print(\"⚠️  No manual human labels available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8586edd9",
   "metadata": {},
   "source": [
    "### 📊 SecurityEval Evaluation Strategy\n",
    "\n",
    "**Ground Truth Approach:**\n",
    "- Each SecurityEval test case has a **known expected CWE** extracted from the filename (format: `CWE-XXX_author_Y.py`)\n",
    "- All SecurityEval test cases are **vulnerable by design** (`gt_vulnerable = True`)\n",
    "- No external ground truth file is needed - the filename is the source of truth\n",
    "\n",
    "**Metric Calculation:**\n",
    "- **True Positive (TP)**: Tool detected the expected CWE (e.g., `bandit_matches_expected = True`)\n",
    "- **False Negative (FN)**: Tool did NOT detect the expected CWE (e.g., `bandit_matches_expected = False`)\n",
    "- **False Positives**: We use the `*_matches_expected` boolean columns for metric calculations\n",
    "\n",
    "**Handling Additional CWEs:**\n",
    "- Tools may detect **additional CWEs beyond the expected one**\n",
    "- These are tracked in `additional_cwes_detected` column for exploratory analysis\n",
    "- **Important**: Additional CWEs are **NOT penalized** as false positives in metric computation\n",
    "- Rationale: SecurityEval test cases may contain multiple vulnerabilities; we only validate detection of the primary expected CWE\n",
    "- This follows the SecurityEval evaluation methodology where the focus is on detecting the targeted vulnerability\n",
    "\n",
    "**Summary:**\n",
    "- Use `*_matches_expected` columns for calculating Precision, Recall, F1-Score\n",
    "- Analyze `additional_cwes_detected` separately to understand tool coverage\n",
    "- This approach prevents unfair penalization for detecting legitimate vulnerabilities not in the expected set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261ddd5",
   "metadata": {},
   "source": [
    "### Validation and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "46ecaeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GROUND TRUTH LABELING SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total workflows: 84\n",
      "Labeled workflows: 84 (100.0%)\n",
      "Unlabeled workflows: 0 (0.0%)\n",
      "\n",
      "Labeling by prompt type:\n",
      "  Manual: 42/42 labeled (100.0% if total > 0 else 0)\n",
      "  SecurityEval: 42/42 labeled (100.0% if total > 0 else 0)\n",
      "\n",
      "Ground truth vulnerability distribution:\n",
      "  Vulnerable: 29 (34.5% if labeled_workflows > 0 else 0)\n",
      "  Not vulnerable: 55 (65.5% if labeled_workflows > 0 else 0)\n",
      "\n",
      "CWE statistics:\n",
      "  Workflows with CWE labels: 63\n",
      "  Total CWE labels: 63\n",
      "  Average CWEs per vulnerable workflow: 1.00\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "SecurityEval Match Metrics:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "SecurityEval workflows with expected CWE: 42\n",
      "\n",
      "Tool Detection of Expected CWE:\n",
      "  Bandit: 3 / 42 (7.1%)\n",
      "  Semgrep: 3 / 42 (7.1%)\n",
      "  AST: 3 / 42 (7.1%)\n",
      "  Combined: 7 / 42 (16.7%)\n",
      "\n",
      "Additional CWEs Detected (exploratory findings):\n",
      "  Total additional CWEs: 68\n",
      "  Workflows with additional CWEs: 42\n",
      "  Note: These are NOT counted as false positives\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GROUND TRUTH LABELING SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Overall counts\n",
    "total_workflows = len(df_labeled)\n",
    "labeled_workflows = df_labeled['gt_source'].notna().sum()\n",
    "unlabeled_workflows = total_workflows - labeled_workflows\n",
    "\n",
    "print(f\"\\nTotal workflows: {total_workflows}\")\n",
    "print(f\"Labeled workflows: {labeled_workflows} ({labeled_workflows/total_workflows*100:.1f}%)\")\n",
    "print(f\"Unlabeled workflows: {unlabeled_workflows} ({unlabeled_workflows/total_workflows*100:.1f}%)\")\n",
    "\n",
    "# By prompt type\n",
    "print(\"\\nLabeling by prompt type:\")\n",
    "for prompt_type in ['Manual', 'SecurityEval']:\n",
    "    mask = df_labeled['prompt_type'] == prompt_type\n",
    "    total = mask.sum()\n",
    "    labeled = (df_labeled[mask]['gt_source'].notna()).sum()\n",
    "    print(f\"  {prompt_type}: {labeled}/{total} labeled ({labeled/total*100:.1f}% if total > 0 else 0)\")\n",
    "\n",
    "# Vulnerability distribution\n",
    "print(\"\\nGround truth vulnerability distribution:\")\n",
    "vulnerable_count = df_labeled[df_labeled['gt_source'].notna()]['gt_vulnerable'].sum()\n",
    "not_vulnerable_count = labeled_workflows - vulnerable_count\n",
    "print(f\"  Vulnerable: {vulnerable_count} ({vulnerable_count/labeled_workflows*100:.1f}% if labeled_workflows > 0 else 0)\")\n",
    "print(f\"  Not vulnerable: {not_vulnerable_count} ({not_vulnerable_count/labeled_workflows*100:.1f}% if labeled_workflows > 0 else 0)\")\n",
    "\n",
    "# CWE statistics\n",
    "print(\"\\nCWE statistics:\")\n",
    "labeled_df = df_labeled[df_labeled['gt_source'].notna()]\n",
    "with_cwes = sum(1 for cwes in labeled_df['gt_cwes'] if len(cwes) > 0)\n",
    "total_cwes = sum(len(cwes) for cwes in labeled_df['gt_cwes'])\n",
    "print(f\"  Workflows with CWE labels: {with_cwes}\")\n",
    "print(f\"  Total CWE labels: {total_cwes}\")\n",
    "if with_cwes > 0:\n",
    "    print(f\"  Average CWEs per vulnerable workflow: {total_cwes/with_cwes:.2f}\")\n",
    "\n",
    "# SecurityEval-specific metrics\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"SecurityEval Match Metrics:\")\n",
    "print(\"-\" * 80)\n",
    "securityeval_labeled = df_labeled[\n",
    "    (df_labeled['prompt_type'] == 'SecurityEval') & \n",
    "    (df_labeled['expected_cwe'].notna()) & \n",
    "    (df_labeled['expected_cwe'] != '')\n",
    "]\n",
    "\n",
    "if len(securityeval_labeled) > 0:\n",
    "    print(f\"\\nSecurityEval workflows with expected CWE: {len(securityeval_labeled)}\")\n",
    "    \n",
    "    # Match rates\n",
    "    print(f\"\\nTool Detection of Expected CWE:\")\n",
    "    print(f\"  Bandit: {securityeval_labeled['bandit_matches_expected'].sum()} / {len(securityeval_labeled)} ({securityeval_labeled['bandit_matches_expected'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Semgrep: {securityeval_labeled['semgrep_matches_expected'].sum()} / {len(securityeval_labeled)} ({securityeval_labeled['semgrep_matches_expected'].mean()*100:.1f}%)\")\n",
    "    print(f\"  AST: {securityeval_labeled['ast_matches_expected'].sum()} / {len(securityeval_labeled)} ({securityeval_labeled['ast_matches_expected'].mean()*100:.1f}%)\")\n",
    "    print(f\"  Combined: {securityeval_labeled['combined_matches_expected'].sum()} / {len(securityeval_labeled)} ({securityeval_labeled['combined_matches_expected'].mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Additional CWEs\n",
    "    total_additional = sum(len(cwes) for cwes in securityeval_labeled['additional_cwes_detected'])\n",
    "    workflows_with_additional = sum(1 for cwes in securityeval_labeled['additional_cwes_detected'] if len(cwes) > 0)\n",
    "    \n",
    "    print(f\"\\nAdditional CWEs Detected (exploratory findings):\")\n",
    "    print(f\"  Total additional CWEs: {total_additional}\")\n",
    "    print(f\"  Workflows with additional CWEs: {workflows_with_additional}\")\n",
    "    print(f\"  Note: These are NOT counted as false positives\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No SecurityEval workflows with expected CWE labels\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6816fa25",
   "metadata": {},
   "source": [
    "## 3. Export Labeled Dataset and Labeling Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1182a68b",
   "metadata": {},
   "source": [
    "### Export Evaluation Labeled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f27566d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Labeled dataset exported to: d:\\Vincy-Certificates\\AIDA\\Winter'25\\Thesis\\Prototype\\Notebooks\\data\\evaluation_labeled.csv\n",
      "  Total records: 84\n",
      "  Labeled records: 84\n",
      "\n",
      "  New columns added:\n",
      "    - expected_cwe (SecurityEval only)\n",
      "    - bandit_cwes, semgrep_cwes, ast_cwes, combined_cwes (initial detection)\n",
      "    - all_cwes_across_workflow (initial + all iterations)\n",
      "    - bandit_matches_expected, semgrep_matches_expected, ast_matches_expected, combined_matches_expected\n",
      "    - expected_cwe_found_anywhere (TRUE if found at any point in workflow)\n",
      "    - additional_cwes_detected\n"
     ]
    }
   ],
   "source": [
    "# Convert list columns to string for CSV export\n",
    "df_export = df_labeled.copy()\n",
    "list_columns = ['gt_cwes', 'bandit_cwes', 'semgrep_cwes', 'ast_cwes', 'combined_cwes', 'all_cwes_across_workflow', 'additional_cwes_detected']\n",
    "for col in list_columns:\n",
    "    if col in df_export.columns:\n",
    "        df_export[col] = df_export[col].apply(lambda x: json.dumps(x) if isinstance(x, list) else '[]')\n",
    "\n",
    "# Export labeled dataset\n",
    "labeled_path = DATA_DIR / 'evaluation_labeled.csv'\n",
    "df_export.to_csv(labeled_path, index=False)\n",
    "\n",
    "print(f\"✓ Labeled dataset exported to: {labeled_path}\")\n",
    "print(f\"  Total records: {len(df_export)}\")\n",
    "print(f\"  Labeled records: {df_export['gt_source'].notna().sum()}\")\n",
    "print(f\"\\n  New columns added:\")\n",
    "print(f\"    - expected_cwe (SecurityEval only)\")\n",
    "print(f\"    - bandit_cwes, semgrep_cwes, ast_cwes, combined_cwes (initial detection)\")\n",
    "print(f\"    - all_cwes_across_workflow (initial + all iterations)\")\n",
    "print(f\"    - bandit_matches_expected, semgrep_matches_expected, ast_matches_expected, combined_matches_expected\")\n",
    "print(f\"    - expected_cwe_found_anywhere (TRUE if found at any point in workflow)\")\n",
    "print(f\"    - additional_cwes_detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c544870d",
   "metadata": {},
   "source": [
    "### Create Labeling Candidates for Manual Workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d104f8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating labeling candidates from 42 Manual workflows...\n",
      "  Workflows with detected vulnerabilities: 13\n",
      "  Workflows with zero vulnerabilities: 29\n",
      "  Sampled zero-vulnerability workflows: 10\n",
      "\n",
      "Total labeling candidates: 23\n"
     ]
    }
   ],
   "source": [
    "def extract_system_detected_cwes(row) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract all system-detected CWEs from initial detection columns.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row\n",
    "        \n",
    "    Returns:\n",
    "        List of unique CWE IDs\n",
    "    \"\"\"\n",
    "    all_cwes = set()\n",
    "    \n",
    "    cwe_columns = [\n",
    "        'initial_detection_bandit_cwes',\n",
    "        'initial_detection_semgrep_cwes',\n",
    "        'initial_detection_ast_cwes'\n",
    "    ]\n",
    "    \n",
    "    for col in cwe_columns:\n",
    "        if col in row.index:\n",
    "            cwes = parse_cwe_list(row[col])\n",
    "            all_cwes.update(cwes)\n",
    "    \n",
    "    return sorted(list(all_cwes))\n",
    "\n",
    "\n",
    "# Get manual workflows\n",
    "df_manual = df_labeled[df_labeled['prompt_type'] == 'Manual'].copy()\n",
    "\n",
    "print(f\"Creating labeling candidates from {len(df_manual)} Manual workflows...\")\n",
    "\n",
    "# Extract system-detected CWEs\n",
    "df_manual['system_detected_cwes'] = df_manual.apply(extract_system_detected_cwes, axis=1)\n",
    "\n",
    "# Separate workflows with and without detected vulnerabilities\n",
    "df_manual_with_vulns = df_manual[df_manual['vulnerabilities_found'] > 0]\n",
    "df_manual_zero_vulns = df_manual[df_manual['vulnerabilities_found'] == 0]\n",
    "\n",
    "print(f\"  Workflows with detected vulnerabilities: {len(df_manual_with_vulns)}\")\n",
    "print(f\"  Workflows with zero vulnerabilities: {len(df_manual_zero_vulns)}\")\n",
    "\n",
    "# Sample zero-vulnerability workflows\n",
    "sample_size = min(MANUAL_ZERO_VULN_SAMPLE_SIZE, len(df_manual_zero_vulns))\n",
    "df_manual_zero_sample = df_manual_zero_vulns.sample(\n",
    "    n=sample_size,\n",
    "    random_state=RANDOM_SEED\n",
    ") if sample_size > 0 else pd.DataFrame()\n",
    "\n",
    "print(f\"  Sampled zero-vulnerability workflows: {len(df_manual_zero_sample)}\")\n",
    "\n",
    "# Combine for labeling candidates\n",
    "df_candidates = pd.concat([df_manual_with_vulns, df_manual_zero_sample], ignore_index=True)\n",
    "\n",
    "print(f\"\\nTotal labeling candidates: {len(df_candidates)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96da057b",
   "metadata": {},
   "source": [
    "### Export Labeling Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ab52d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Labeling candidates exported to: d:\\Vincy-Certificates\\AIDA\\Winter'25\\Thesis\\Prototype\\Notebooks\\data\\ground_truth\\labeling_candidates_manual.csv\n",
      "  Total candidates: 23\n",
      "  With detected vulnerabilities: 13\n",
      "  Without detected vulnerabilities: 10\n"
     ]
    }
   ],
   "source": [
    "# Select columns for labeling\n",
    "candidate_columns = [\n",
    "    'workflow_id',\n",
    "    'prompt',\n",
    "    'llm_response',\n",
    "    'vulnerabilities_found',\n",
    "    'system_detected_cwes',\n",
    "    'total_vulnerabilities_identified',\n",
    "    'total_vulnerabilities_fixed',\n",
    "    'total_vulnerabilities_remaining'\n",
    "]\n",
    "\n",
    "# Filter to available columns\n",
    "available_columns = [col for col in candidate_columns if col in df_candidates.columns]\n",
    "df_candidates_export = df_candidates[available_columns].copy()\n",
    "\n",
    "# Convert list to string for CSV\n",
    "if 'system_detected_cwes' in df_candidates_export.columns:\n",
    "    df_candidates_export['system_detected_cwes'] = df_candidates_export['system_detected_cwes'].apply(\n",
    "        lambda x: json.dumps(x) if isinstance(x, list) else '[]'\n",
    "    )\n",
    "\n",
    "# Export candidates\n",
    "candidates_path = OUTPUT_DIR / 'labeling_candidates_manual.csv'\n",
    "df_candidates_export.to_csv(candidates_path, index=False)\n",
    "\n",
    "print(f\"✓ Labeling candidates exported to: {candidates_path}\")\n",
    "print(f\"  Total candidates: {len(df_candidates_export)}\")\n",
    "print(f\"  With detected vulnerabilities: {(df_candidates_export['vulnerabilities_found'] > 0).sum()}\")\n",
    "print(f\"  Without detected vulnerabilities: {(df_candidates_export['vulnerabilities_found'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224b7b5b",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ca103cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GROUND TRUTH ANNOTATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Generated outputs:\n",
      "  1. Labeled dataset: d:\\Vincy-Certificates\\AIDA\\Winter'25\\Thesis\\Prototype\\Notebooks\\data\\evaluation_labeled.csv\n",
      "     - Total workflows: 84\n",
      "     - Labeled: 84\n",
      "     - Unlabeled: 0\n",
      "\n",
      "  2. Labeling candidates: d:\\Vincy-Certificates\\AIDA\\Winter'25\\Thesis\\Prototype\\Notebooks\\data\\ground_truth\\labeling_candidates_manual.csv\n",
      "     - Total candidates: 23\n",
      "     - For human review and annotation\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Key Features:\n",
      "--------------------------------------------------------------------------------\n",
      "  ✓ SecurityEval ground truth extracted from filename (no external file needed)\n",
      "  ✓ Expected CWE detection tracked via *_matches_expected columns\n",
      "  ✓ Additional CWEs tracked separately (not counted as false positives)\n",
      "  ✓ Ready for metric calculation using match columns\n",
      "\n",
      "Next steps:\n",
      "  ✓ All workflows are labeled!\n",
      "  Ready for evaluation analysis in next notebook (04_rq2_detection_metrics.ipynb)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GROUND TRUTH ANNOTATION COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nGenerated outputs:\")\n",
    "print(f\"  1. Labeled dataset: {DATA_DIR / 'evaluation_labeled.csv'}\")\n",
    "print(f\"     - Total workflows: {len(df_labeled)}\")\n",
    "print(f\"     - Labeled: {df_labeled['gt_source'].notna().sum()}\")\n",
    "print(f\"     - Unlabeled: {(~df_labeled['gt_source'].notna()).sum()}\")\n",
    "\n",
    "print(f\"\\n  2. Labeling candidates: {OUTPUT_DIR / 'labeling_candidates_manual.csv'}\")\n",
    "print(f\"     - Total candidates: {len(df_candidates_export)}\")\n",
    "print(f\"     - For human review and annotation\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Key Features:\")\n",
    "print(\"-\" * 80)\n",
    "print(\"  ✓ SecurityEval ground truth extracted from filename (no external file needed)\")\n",
    "print(\"  ✓ Expected CWE detection tracked via *_matches_expected columns\")\n",
    "print(\"  ✓ Additional CWEs tracked separately (not counted as false positives)\")\n",
    "print(\"  ✓ Ready for metric calculation using match columns\")\n",
    "\n",
    "print(\"\\nNext steps:\")\n",
    "if unlabeled_workflows > 0:\n",
    "    manual_unlabeled = df_labeled[\n",
    "        (df_labeled['prompt_type'] == 'Manual') & \n",
    "        (~df_labeled['gt_source'].notna())\n",
    "    ].shape[0]\n",
    "    \n",
    "    if manual_unlabeled > 0:\n",
    "        print(f\"  1. Review and label {manual_unlabeled} unlabeled Manual workflows\")\n",
    "        print(f\"  2. Update manual labels file: {MANUAL_LABELS}\")\n",
    "        print(f\"  3. Re-run this notebook to update evaluation_labeled.csv\")\n",
    "    else:\n",
    "        print(\"  ✓ All Manual workflows are labeled!\")\n",
    "        print(\"  ✓ All SecurityEval workflows auto-labeled from filename\")\n",
    "        print(\"  Ready for evaluation analysis\")\n",
    "else:\n",
    "    print(\"  ✓ All workflows are labeled!\")\n",
    "    print(\"  Ready for evaluation analysis in next notebook (04_rq2_detection_metrics.ipynb)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7774cd99",
   "metadata": {},
   "source": [
    "## Additional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06b62814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed labeling status by prompt type:\n",
      "============================================================\n",
      "\n",
      "SecurityEval:\n",
      "  Total: 42\n",
      "  Labeled: 42 (100.0%)\n",
      "  Unlabeled: 0 (0.0%)\n",
      "  Ground truth vulnerable: 8 (19.0%)\n",
      "  Ground truth not vulnerable: 34 (81.0%)\n",
      "\n",
      "Manual:\n",
      "  Total: 42\n",
      "  Labeled: 42 (100.0%)\n",
      "  Unlabeled: 0 (0.0%)\n",
      "  Ground truth vulnerable: 21 (50.0%)\n",
      "  Ground truth not vulnerable: 21 (50.0%)\n"
     ]
    }
   ],
   "source": [
    "# Show distribution of labeled vs unlabeled by prompt type\n",
    "print(\"\\nDetailed labeling status by prompt type:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for prompt_type in df_labeled['prompt_type'].unique():\n",
    "    df_type = df_labeled[df_labeled['prompt_type'] == prompt_type]\n",
    "    total = len(df_type)\n",
    "    labeled = df_type['gt_source'].notna().sum()\n",
    "    unlabeled = total - labeled\n",
    "    \n",
    "    print(f\"\\n{prompt_type}:\")\n",
    "    print(f\"  Total: {total}\")\n",
    "    print(f\"  Labeled: {labeled} ({labeled/total*100:.1f}%)\")\n",
    "    print(f\"  Unlabeled: {unlabeled} ({unlabeled/total*100:.1f}%)\")\n",
    "    \n",
    "    if labeled > 0:\n",
    "        vulnerable = df_type[df_type['gt_source'].notna()]['gt_vulnerable'].sum()\n",
    "        print(f\"  Ground truth vulnerable: {vulnerable} ({vulnerable/labeled*100:.1f}%)\")\n",
    "        print(f\"  Ground truth not vulnerable: {labeled - vulnerable} ({(labeled-vulnerable)/labeled*100:.1f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
